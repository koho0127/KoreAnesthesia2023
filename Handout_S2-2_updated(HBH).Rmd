---
title: "Statistical Round Session: R code - 2023 KoreAnesthesia"
author: "KJA Statistical Round Members"
date: "2023-11-11"
output:  
  word_document:
    number_sections: yes
    toc: yes
    toc_depth: 5
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# SESSION 1: R SOFTWARE (PREPARE FOR A LONG JOURNEY)

## Session 1-1: R software, RStudio

## Session 1-2: Understand R: CSV file format, Packages, List, data frame, object
### Data Preparation

Set working directory: The directory where the sample_data exists.
```{r, eval=FALSE}
setwd(r"(Your\WorkingDirectory\Here)")
```


```{r, echo=FALSE}
setwd("C:/Users/user/Desktop/2023 SR workshop")

# Change R output in English
Sys.setenv(LANG = "en")
```

Import CSV format data.
```{r}
#Read CSV file
mydata = read.csv("sample_data_23workshop4.csv", header = TRUE, fileEncoding = "UTF-8-BOM", fill = TRUE)

```

### Installing a package 

R package의 종류  
1. Base Packages: R software 설치시 자동으로 설치되는 package들. R 시작시 함께 load되기 때문에 포함된 명령어를 그대로 사용하면 된다. (예: base, datasets)  
2. Recommended Packages: R software 설치시 자동으로 설치되나, R 시작시 load되지 않기 때문에 사용하려면R로 불러오기를 해야 한다. (예: MASS)  
3. Other Packages: 필요에 따라 특정 Package를 설치한 뒤, 불러와서 사용한다. (예: dplyr, ggplot2)

Package의 설치 (대소문자 주의)
```{r, eval=FALSE}
install.packages("PackageName")
```

Package를 load하는 방법
```{r, eval=FALSE}
library("PackageName")
```

예를 들어, 간단한 power analysis를 가능하게 해주는 "pwr" package를 설치해보자.  
```{r, eval=FALSE}
install.packages("pwr")
```

"pwr" package를 불러와 보자
```{r}
library(pwr)
```

### Vector, data frame, List
  
R이 자료를 처리하기 위해 저장하는 구조는 여러가지가 있다. 보통 Excel을 통해 자료를 저장하여 통계 프로그램에서 사용하는 것이 익숙하기 때문에, 이런 구조가 생소하겠지만, R은 이런 구조들을 사용하여 결과를 출력하여 저장해 두기 때문에, 특정 결과만 추출하여 다른 통계에 이용하기 위해서는 알아 둘 필요가 있다.
하나의 값에서 부터 vector, data frame, list등 R에서 다루는 자료를 object라고 한다.  

1. vector  
한가지 변수 형태들이 나열되어 저장된 형태이다.  
```{r}
name <- c("a", "b", "c", "d")

value <- c(1, 2, 3, 4)


name

value
```

2. data frame  
Excel에서 자료를 저장하는 형태라고 이해하면 쉽다.  
행과 열로 구성되어 있으며, 1행이나 1열로 이루어진 자료도 구성이 가능하다.  
Excel과의 차이는 행이름 (row name)이나 열 이름 (column name)을 따로 가지고 있다는 점이다. (Excel은 보통 1행에 열 이름 - 흔히 변수이름 - 을 저장하고, 1열에는 자료 번호를 저장한다)  
일반적으로 자료를 불러와서 통계분석을 시행할 때는 data frame형태의 자료를 이용하게 된다.  
```{r}
myexample <- data.frame(name, value)

myexample
```

3. List  
List는 여러개의 vector, data frame을 모두 포함할 수 있으며, 여기에 설명되지 않은 다른 형태의 자료 구조도 모두 포함할 수 있다. 대부분의 통계 결과는 List 형태로 출력이 되며, 이를 지정하여 특정 값 (예를 들면, 평균이나 P값)을 추출 해 낼 수 있다.
```{r}
mylist <- list(session = "statistical round session", 
               person = 30,
               seat = c(10, 20, 30))
mylist

mylist$session

mylist$person

mylist$seat

mylist$seat[2]

```

## Session 1-3: R commend structure

R의 통계분석은 직접 필요한 명령어를 이용하여 coding을 해야 한다다.  
Coding에 필요한 모든 문법을 외워서 시행하는 것이 가장 이상적이겠지만, 명령어 각각이 다른 형식의 coding을 요구하는 경우가 흔하기 때문에, 기존에 구성되어 있는 명령어 예제를 적용하려는 자료에 맞추어 변형만 하여도 대부분의 통계 분석이 가능하다.  
이정도의 coding을 편집하기 위해서는 기본적으로 대부분의 명령어가 어떤 형태로 이루어져 있는지 이해하는 것이 필요하다.  
  
1. Assignment  
변수에 값을 할당하는 방법이다. 기호 = 혹은, <-, ->를 사용한다.  
2. Function call  
함수를 호출하여 작업을 수행하고 object에 할당하는 방법이다.  
```{r}
result <- mean(c(5, 8, 12))

result
```
3. Conditional statements  
Excel에서 if명령어를 사용하는 것과 유사하다.  
```{r, eval=FALSE}
if (x > 0){
  print("Postive")
} else if (x == 0){
  print("zero")
} else {
  print("negative")
}
```
4. Loop  
반복하여 작업이 필요할 때 사용하는 방법이다.  
for 혹은 while과 같은 반복문을 사용할 수 있다.
```{r}
for(i in 1:5){
  print(i)
}
```
5. Data structure  
앞서 살펴본 방법들로 자료를 저장할 수 있다.  
  
6. Package usage  
R에서 기본적으로 제공되지 않는 기능은 Package를 설치하여 확장 할 수 있다. 이들은 package 설치 후 해당 package를 loading해야 사용이 가능하다.  
특정 명령어를 이용하여 통계분석을 시행할 때는, 어떤 방식으로 계산을 해야 하는지 지정을 해줘야 하며, 이것들은 argument를 통해 가능하다. 다만 package마다 argument를 설정하는 방식이 조금씩 다르기 때문에, 기존에 완성된 code를 복사하여 자신의 상황에 맞도록 수정하는 것이 편리하다.  
예를 들어, 그래프를 그리기 위해 자주 사용되는 package는 ggplot2라는 것이 있으며며, 이를 이용하여 산점도를 그린다면 다음과 같은 명령어 형식을 사용할 수 있다.
```{r, eval=FALSE}
#installing "ggplot2"
if (!requireNamespace("ggplot2", quietly = TRUE)) {
  install.packages("ggplot2")
}
```
  
이제 ggplot2를 load하여 간단한 그래프를 그려보자.
```{r}
library(ggplot2)

ggplot(data = myexample, aes(x = name, y = value)) + geom_point()
```

얼핏 보면 생소하고 어려운 듯 하나, 자세히 살펴보면 x에 x축에 해당되는 변수명을, y에 y축에 해당하는 변수명을 넣어주면 다른 자료들의 scatter plot을 그릴수 있다. sample csv file에는 여러개의 변수들이 있으며, 이들 중 "vas1"과 "vas2"사이의 산점도 (scatter plot)을 그린다면 다음과 같은 명령어를 사용하면 된다.
```{r}
ggplot(data = mydata, aes(x = paired.pre, y = paired.post)) + geom_point()
```

ggplot2를 포함하여 R에서 통계분석을 할때, 많은 도움이 되는 몇가지 package들을 소개한다.  
  
1. ggplot2  
앞서 소개한 바와 같이 그래프를 작성할때 매우 유용한 package이다.  
  
2. dplyr  
R은 한번에 한가지씩 처리를 하는 방식으로 coding이 된다. 예를 들어 자료에서 특정 조건에 맞는 경우들을 골라내서, 평균을 계산하고 새로운 data로 저장하는 작업을 R에서 수행하려면, 조건에 맞게 추출한 자료를 저장하고, 그 자료를 불러와서 평균을 계산해서 그 값들을 저장하고, 저장된 값을 data형태로 다시 저장을 해야 한다. 이런 일련의 과정을 연속적으로 수행하게 해주는 package가 dplyr이다. 
  
 3. tidyverse  
 tidyverse는 dplyr과 ggplot2를 포함하고 tidyr, readr, purrr, tibble, stringr, forcats와 같은 여러개의 package를 모아서, 통계분석 작업을 더 효율적이고 일관된 방식으로 수행할 수 있도록도와준다. 다만, 이와 같은 package들을 모두 load해서 사용하게 되면 일부 저성능 컴퓨터에서는 처리 속도가 지연될 수 있기 때문에, 필요한 package를 load하거나 잠시 불러와서 사용하는 방법도 고려해야 한다.   
   
  
Package를이용하는 두가지 방법  
첫번째는 library()를 이용하여 컴퓨터의 메모리에 전체 package를 상주시킨 뒤 필요한 명령어를 사용하는 방법이다. 이방법은 한번 package를 load하면 언제든지 포함된 명령어를 사용할 수 있어 편리하지만, 저사양 컴퓨터나 아주 복잡한통계 분석을 시행할 때는 컴퓨터의 메모리를 차지하기 때문에 불리할 수 있다.  
두번째는 package::command형태로 해당 명령어를 실행할때만 package를 지정하여 시행하는 방법이다. coding시 입력을 매번 해야 하는 번거로움이 있지만, 메모리를 아낄 수 있는 장점이 있다. 전체 분석에 자주 사용하는 경우가 아니라면 추천할 만 하다. 

# SESSION 2: DEPARTURE TO CODING FOR A STATISTICAL ANALYSIS

## Session 2-1: Basic concepts of statistical analysis

## Session 2-2: Descriptive statistics, Normality test, Equal variance test, Basic data explorations
  
Session 1에서 불러온 mydata의 구조를 살펴보자.  
mydata를 입력하면 불러온 자료의 일부를 보여준다.  
```{r, eval=FALSE}
mydata
```

자료의 일부분만 살펴보기 위해선 다음과 같은 방법을 사용할 수 있다.  
결과 출력의 길이가 길기 때문에, 결과는 생략한다.
```{r, eval=FALSE}
# Show the first 6 rows
head(mydata)

# Show the first 3 rows
head(mydata, n=3)

# Show the last 6 rows
tail(mydata)

# Show 4 - 6 rows of the data
mydata[4:6,]

# Show 3~5 columns of the data
mydata[,3:5]
```
  
mydata의 구조를 확인하는 방법은 다음과 같다.  
자료가 몇개의 행과 열로 이루어져 있는지 확인하는 방법.
```{r}
# dimension
dim(mydata)
```
변수의 개수를 확인하는 방법.
```{r}
# No of columns (No of variables)
ncol(mydata)

# No of variables (length of the first row)
length(mydata)
```
입력된 개수 (표본수)를 확인하는 방법.
```{r}
# No of rows (No of cases: excluding row of variable names)
nrow(mydata)

# length of a specific variable - case.no vs. mw.group
length(mydata$case.no)
```
변수들의 특성을 확인하는 방법.  
(int: integer, chr: character, num: number)
```{r}
# the characters of variables
str(mydata)

mydata$group<-as.factor(mydata$group)
str(mydata$group)
```
변수의 descriptive statistics와 missing value개수를 확인하는 방법.
```{r}
# Summarized values 
summary(mydata)

# 
Hmisc::describe(mydata)
Hmisc::describe(mydata$obs1)
```

변수명을 확인하는 방법
```{r}
# list of variables
names(mydata)

# Metadata of the imported data
attributes(mydata)
```

결측치

```{r}
is.na(mydata)
options(max.print=1000)

sum(is.na(mydata))


na.count <- apply(mydata, 2, function(x) sum(is.na(x)))  #apply(array, 방향, 함수) 1: 행, 2: 열
na.count

mydata[5, 'medication'] <- NA
# na.count <- apply(mydata, 2, function(x) sum(is.na(x))) 
na.count

mydata[5, 'medication'] <- 1

```

이상치
```{r}

boxplot(mydata)
boxplot(mydata[,c(3:5,9:12)])

boxplot(mydata$obs2)
boxplot(mydata$obs2)$stats
summary(mydata$obs2)

with_out<-boxplot(mydata$obs2)
with_out$out

which(mydata$obs2>summary(mydata$obs2)[5] + 1.5*IQR(mydata$obs2))
which(mydata$obs2<summary(mydata$obs2)[2] - 1.5*IQR(mydata$obs2))



install.packages("outliers")
library(outliers)

outlier(mydata[,3:12])
outlier(mydata[,3:12], opposite=T)

```




### Descriptive statistics and distribution

자료의 형태를 확인하는 방법은, str을 사용하는 것도 가능하지만, skim이라는 package를 사용하면 여러가지의 정보를 한번에 할 수 있다. skim은 기본적으로 dplyr을 이용하기 때문에 두개의 package가 모두 설치되어 있어야 한다. 다음은 dplyr과 skimr이 설치되어 있지 않은 경우 설치를 진행해주는 code이다. 
```{r}
if (!requireNamespace("dplyr", quietly = TRUE)) {
  install.packages("dplyr")
}

if (!requireNamespace("skimr", quietly = TRUE)) {
  install.packages("skimr")
}
```

skimr에 포함되어 있는 명령어 skim을 이용하면 다음과 같은 summary statistics를 얻을수 있다.
```{r}
skimr::skim(mydata)
```

군 별로 나누어져 있는 자료의 descriptive statistics는 psych라는 package의 desribeBy명령어를 사용하거나 dplyr의 filter 명령어로 구할 수 있다. 다음은 psych package를 이용한 방법이다.

```{r}
if (!requireNamespace("psych", quietly = TRUE)) {
  install.packages("psych")
}

psych::describeBy(mydata$t_test.value, group = mydata$group )


moonBook::mytable(group~ . ,mydata, method=3,,max.ylev=4)   
table<- moonBook::mytable(group~ . ,mydata, method=2, max.ylev=4)   
moonBook::mycsv(table,file="table.csv")



```
  
Histogram을 확인하는 방법은 다음과 같다.
```{r}
hist(mydata$t_test.value)
lines(density(mydata$t_test.value))
```
위 그래프에서 density가 잘 나오지 않는다. density plot만 확인하려면 다음의 코드를 이용한다.
```{r}
plot(density(mydata$t_test.value))
```

### Normality test


  
R에서 기본으로 제공하는 정규성 검정 방법은 Shapiro-Wilk test (shapiro.test()), Kolmogorov-Smirnov test (ks.test()), Anderson-Darling test (ad.test()), Lilliefors test (lillie.test()), Jarque-Bera test(jarque.bera.test())가 있다.  
다음의 code를 이용하면 숫자형변수들의 정규성 검정을 한번에 실행 할 수 있다.  
```{r}
library(dplyr)

mydata %>% # "%>%"는 dplyr의 연속적인 계산을 명령하는 기호,Pipe operator.
  dplyr::select(t_test.value,
         paired.pre, # 숫자형변수만 선택하는 dplyr을 이용한 작업이다.    
         paired.post, # 알아보기 쉽게 줄바꿈을 하면, 
         observed
         ) %>%
  apply(2, shapiro.test) -> normality.result     #apply(array, 방향, 함수) 1: 행, 2: 열
   
  
normality.result

```
위의 code는apply라는 명령어를 사용하였다.  
apply의 argument는 다음과 같다.  
  apply(data, margin, function)  
  data: pipeline operator를 이용하였기 때문에 data는 지정하지 않아도 이전 단계의 자료를 사용한다.  
  margin: 1은 행단위의 자료를, 2는 열단위로 자료를 이용한다고 지정한다.  
  function: 시행할 명령어를 넣어준다.
  
rstatix package에서 제공하는 shapiro_test()는 기본 명령어인 shapiro.test를 이용하여 dplyr의 pipeline operator를 쉽게 사용할 수 있게 해주며, grouped data를 이용 할 수 있다.  
```{r}
if (!requireNamespace("rstatix", quietly = TRUE)) {
  install.packages("rstatix")
}

mydata %>%
  group_by(group) %>%
  rstatix::shapiro_test(t_test.value)
```

  
R에서 QQ plot은 기본 함수로 그릴 수 있다.  
```{r}
qqnorm(mydata$t_test.value)
qqline(mydata$t_test.value)
```
ggpubr package에서 제공하는 ggqqplot를 이용하면 해석이 조금 더 용이하다.
```{r}
if (!requireNamespace("ggpubr", quietly = TRUE)) {
  install.packages("ggpubr")
}
ggpubr::ggqqplot(mydata$t_test.value)
```

```{r, eval=FALSE, echo=FALSE}
qqnorm 에서 분위수를 구할 때 ppoints 함수를 사용합니다. ppoints 함수는 순위기반표준화(rank-based normalization)의 일종입니다. 순위기반표준화 방법에는 Van der waerden법, Blom법, Rankit법, Tukey법 등이 있습니다. R에서 제공하는 ppoints 함수는 n이 10 이하일 때는 Blom 법을, 10 초과일 때는 Rankit 법을 사용합니다. 각 방법에 대해서는 아래 표에 간단히 정리해 놓았습니다. 



*SPSS에서 Q-Q plot을 그릴 때는 아래 네 방법 중 선택할 수 있습니다. 



Procedure         Year    Formula 

Van der Waerden   1952    r / (n+1) 

Blom              1954    (r - 3/8) / (n + 1/4) 

Rankit            1956    (r - 1/2) / n 

Tukey             1962    (r - 1/3) / (n + 1/3)

where r is the rank, ranging from 1 to n

(표 출처) Impact of Rank-Based Normalizing Transformations on the Accuracy of Test Scores, Shira R. Solomon, 2009, Journal of Modern Applied Statistical Methods

```


### Equal variance test (Homogeneity of variance test)

R에서 기본 제공하는 equal variance test는 Bartlett test와 Fligner test이며, SPSS등에서 사용되고 있는 더 robust한 방법인 Leven's test는 "car" package를 설치하거나, 기본으로 설치되는 DescTools를 이용하여여 사용할 수 있다.
```{r}
 # For these test, grouping variable should not be a quantitative variable.
mydata$group <- as.factor(mydata$group)

# Bartlett test
bartlett.test(t_test.value ~ group, data = mydata)

# Fligner test
fligner.test(t_test.value ~ group, data = mydata)

# Levene's test
if (!requireNamespace("car", quietly = TRUE)) {
  install.packages("car")
}

car::leveneTest(t_test.value ~ group, data = mydata)

DescTools::LeveneTest(t_test.value ~ group, data = mydata)
```


https://r4ds.hadley.nz/eda

### Crude data exploration

변수들간의 관계에 대한 정보는 이후 통계 분석 과정에 많은 도움을 준다. 변수들간의 관계를 파악하기 쉬운 방법은 산점도(scatter plot)을 이용하거나 correlation analysis를 이용한다.  
R package들 중 이런 정보를 얻기 쉽게 해주는 명령어를 제공하는 몇가지를 소개한다.  
```{r}
# Basic scatter plot between two variables
plot(mydata$paired.pre, mydata$paired.post)

# advanced scatter plot 
car::scatterplot(paired.pre ~ paired.post, data = mydata)

# Scatter plot by groups
car::scatterplot(paired.pre ~ paired.post|group, data = mydata)
```
  
변수들 간의 관계를 알아보기 위해 correlation analysis를 이용할 수 있지만, 전체 자료에서의 관계를 한눈에 파악하기 위해 correlation plot을 이용하는 방법을소개한다. 

correlation plot
```{r}
mydata$group <- as.numeric(mydata$group)
mydata<-na.omit(mydata)
ggcorrplot::ggcorrplot(cor(mydata[,2:12]),
                       p.mat = ggcorrplot::cor_pmat(mydata[,2:12]),
                       type = "lower",
                       method = "circle",
                       tl.cex = 8,
                       tl.srt = 90)


cor.test(mydata$obs1,mydata$obs3)
x<-cor(mydata[,2:12])
corrplot::corrplot(x)
```


```{r,warning=FALSE, message=FALSE}
if (!requireNamespace("tidyverse", quietly = TRUE)) {
  install.packages("tidyverse")
}
if (!requireNamespace("corrr", quietly = TRUE)) {
  install.packages("corrr")
}
if (!requireNamespace("PerformanceAnalytics", quietly = TRUE)) {
  install.packages("PerformanceAnalytics")
}

library(tidyverse)
library(corrr)
library(PerformanceAnalytics)
```


```{r}
res.cor<-correlate(mydata[,2:12])
res.cor
res.cor %>% fashion()



mydata[,2:12] %>%
  correlate(method = "pearson") %>%
  network_plot(min_cor = 0.1,
               colors = c("red", "white", "green"),
               repel = TRUE,
               curved = TRUE)


chart.Correlation(mydata[,2:12])



```

## Session 2-3: T-test (independent, paired), chi-square test, one-way ANOVA

### Independnet T-test
  
T-test를 위한 자료는 t_test.group과 t_test.value이다.  
  
1. Normality test  
```{r}
mydata %>%
  filter(group == 1) %>%
  select(t_test.value) %>%
  apply(2, shapiro.test)

mydata %>%
  filter(group == 2) %>%
  select(t_test.value) %>%
  apply(2, shapiro.test)
```
  
2. Homogeneity of variance test
```{r}
mydata$group <- as.factor(mydata$group)

car::leveneTest(t_test.value ~ group, data = mydata)
```
  
3. t-test
  
등분산성이 확립되었을 때
```{r}
t.test(t_test.value ~ group,
       data = mydata,
       alternative = "two.sided",
       paired = FALSE,
       var.equal = TRUE
       ) -> t.test.res

t.test.res

# Effect size: Cohen's d
if (!requireNamespace("effectsize", quietly = TRUE)) {
  install.packages("effectsize")
}

effectsize::cohens_d(t_test.value ~ group, 
             data = mydata) -> cohend

cohend
```
  
등분산성이 확립되지 않았을 때
```{r}
t.test(t_test.value ~ group,
       data = mydata,
       alternative = "two.sided",
       paired = FALSE,
       var.equal = FALSE
       ) -> t.test.ueq.res

t.test.ueq.res

# Effect size: Cohen's d
effectsize::cohens_d(t_test.value ~ group, 
             data = mydata,
             pooled_sd = TRUE # Default value
             ) -> cohend.ueq

cohend.ueq
```
  
### Paired T-test
  
Paired t-test data: pair_t.pre	pair_t.post  

1. normality test  
```{r}
mydata %>%
  select(paired.pre,	paired.post) %>%
  apply(2, shapiro.test)

qqnorm(mydata$paired.pre)
qqline(mydata$paired.pre)

qqnorm(mydata$paired.post)
qqline(mydata$paired.post)
```
2. paired t-test  
```{r}
t.test(mydata$paired.pre, mydata$paired.post,
       alternative = "two.sided",
       paired = TRUE
       ) -> t.test.pair.res

t.test.pair.res

# Effect size
effectsize::cohens_d(mydata$paired.pre, mydata$paired.post,
                     paired = TRUE) -> cohend.pair

cohend.pair
```
```{r, eval=FALSE}
# the following also works
effectsize::cohens_d(Pair(paired.pre, paired.post) ~ 1, data = mydata)
```

### Chi-square test
  
Chi-square test를 위한 자료: group, chisqr  
  
Table 만드는 방법 1
```{r}
chi.tbl <- xtabs(~group + chisqr, mydata)
addmargins(chi.tbl)
```
  
Table 만드는 방법 2
```{r}
if (!requireNamespace("gmodels", quietly = TRUE)) {
  install.packages("gmodels")
}

gmodels::CrossTable(mydata$group, mydata$chisqr)
```
  
Chi-square test (기본 package)
```{r}
chisq.test(mydata$group, mydata$chisqr,
           correct = TRUE) -> chisq.res

chisq.res

# effect size: Cramér's V
effectsize::cramers_v(mydata$group, mydata$chisqr) -> cramerv

cramerv
```
  

### ANOVA
  
Normality test  

```{r}
mydata %>%
  group_by(medication) %>%
  rstatix::shapiro_test(observed)

```

One-way ANOVA test
```{r}
mydata$medication <- as.factor(mydata$medication)


aov(observed ~ medication, data = mydata) -> one.anova.res

summary(one.anova.res)

# effect size: eta squared
effectsize::eta_squared(one.anova.res) -> one.anova.eta

one.anova.eta

# effet size: Cohen's f
effectsize::cohens_f(one.anova.res) -> one.anova.f

one.anova.f
```


Two-way ANOVA test

```{r}
mydata$group <- as.factor(mydata$group)

aov(observed ~ medication + group + medication*group, data = mydata) -> two.anova.res

summary(two.anova.res)

# effect size: eta squared (Type I & III)
  # Type I
effectsize::eta_squared(two.anova.res) ->two.anova.eta.i

two.anova.eta.i

effectsize::cohens_f(two.anova.res) -> two.anova.f.i

two.anova.f.i  

  # Type III
two.anova.res.iii <- car::Anova(two.anova.res, type = 3) # Two-way ANOVA, type III result

effectsize::eta_squared(two.anova.res.iii) -> two.anova.eta.iii

two.anova.eta.iii

effectsize::cohens_f(two.anova.res.iii)
```

effectsize::cohen_f값은 실제 수기 계산값과 조금 다르다. 아마도, eta squared에서 계산한 값 같다.  
수기 계산은 다음의 식이다.  
 $$f = \sigma_{between-group} / \sigma_{within-group} = \frac{\sqrt{\sum_{k=1}^{K}{(\mu_{k}-\mu)^{2}/K}}}{\sqrt{\sum_{j=1}^{J}\sum_{k}^{K}{(\mu_{jk}-\mu)^{2}/JK}}}$$  
 eta_square와 f의 관계는 다음과 같다.  
 $\eta^{2} = SS_{treat} / SS_{total}$  
$SS_{total} = SS_{treat} + SS_{residual}$  
  
$f = \sqrt{\eta^{2}/(1-\eta^{2})}$  
  
여기서 주의할 점은 two-way ANOVA table의 ss를 계산할때는 평균값의 차이 제곱합에 표본수를 곱해야 한다는 점이다. (reference: How to Perform a Two-Way ANOVA by Hand - Statology.pdf)    
Eta_squared도 SPSS에서와 G\*Power에서 계산한게 다르듯이 패키지 마다 다를 수 있다. (reference: G\*Power manual.pdf, P27)

### Repeated measures ANOVA
  
R의 aov 명령어를 이용하여 RM ANOVA를 시행하려면, 자료의 형태가 long format이어야 가능하다. 다음의 code는 long format으로 자료의 구조를 바꾸어 준다. 
```{r}
tidyr::gather(mydata, 
              ws.factor, # Variable of within-subject factor
              observed,  # observed value at each measurement point
              obs1:obs4,
              factor_key = TRUE
              ) -> mydata.long
```
  
변경된 자료의 구조를 살펴보면, 마지막에 within-subject factor (repeated measures factor)와 observed라는 변수가 생성된 것을 볼 수 있다. Within-subject factor는 obs1, obs2, obs3, obs4와 같이 측정시점의 정보가 담겨져 있고, observed는 해당 측정 시점에서의 측정값이 담겨있다. 즉, 첫번째 case의자료가 다음과 같이 4개의 자료로 바뀐다.    
```{r}
# 1st case wide type data
mydata[1,]

# 1st case long type data
mydata.long[c(1,217, 433, 649),]
```
 
RM ANOVA를 시행하기 위한 기본 가정 (basic assumptions)을 확인한다.  
1. Outliers check
```{r}
mydata.long %>%
  select(ws.factor, observed) %>%
  group_by(ws.factor) %>%
  rstatix::identify_outliers(observed) -> outliers

summary(outliers)

as.data.frame(outliers) %>%
  filter(is.extreme == "TRUE")

```
"is.extreme"에서 TRUE의 개수가 0개이므로 extreme outliers가 없음을 확인할 수 있다. 만약 extreme outlier가 있다면, 자료의 값이 잘못 입력되었는지 확인해보고,  winsorization이 필요하다면, winsorization후 sensitivity analysis까지 계획을 해야 한다.  

  
2. Normality test  
```{r}
mydata.long %>%
  group_by(ws.factor) %>%
  rstatix::shapiro_test(observed)

ggpubr::ggqqplot(mydata.long, "observed", facet.by = "ws.factor")
```

3. Sphericity assumption & ANOVA test  
rstatix의 anova_test를 이용하면, Sphericity assumption의 과정과 결과에 따라 Greenhose-Geisser correction이나 Hyunh-Feldt correction등 보정의 작업을 한번에 수행해준다.  
  
*one way RM ANOVA (ANOVA with one repeated measure factor)*
```{r}
library(rstatix)
anova_test(observed ~ ws.factor + Error(case.no/ws.factor),
           data = mydata.long,
           #effect.size = "ges",
           #effect.size = "pes",
           #type = 1
           #type = 3
           detail = TRUE) -> one.rmanova.res

one.rmanova.res

# ANOVA table (Type III SS) and Generalized Eta-squared measure (ges)
get_anova_table(one.rmanova.res)

one.rmanova.res$`Mauchly's Test for Sphericity`
```
출력되는 ANOVA table에서..  
DFn: Degrees of Freedom in the numerator (i.e. DF effect)  
DFd: Degrees of Freedom in the denominator (i.e., DF error)  
SSn Sum of Squares in the numerator (i.e., SS effect)  
SSd Sum of Squares in the denominator (i.e.,SS error)  
F F-value  
p p-value (probability of the data given the null hypothesis)  
p<.05 Highlights p-values less than the traditional alpha level of .05  
ges Generalized Eta-Squared measure of effect size  
GGe Greenhouse-Geisser epsilon  
p[GGe] p-value after correction using Greenhouse-Geisser epsilon  
p[GGe]<.05 Highlights p-values (after correction using Greenhouse-Geisser epsilon) less than the traditional alpha level of .05  
HFe Huynh-Feldt epsilon  
p[HFe] p-value after correction using Huynh-Feldt epsilon  
p[HFe]<.05 Highlights p-values (after correction using Huynh-Feldt epsilon) less than the traditional alpha level of .05  
W Mauchly's W statistic  
  
*More about Mauchly's Sphericity test*
Mauchly's Test of Sphericity (모쉬리의 구형성검정)은 '모상관행렬은 단위행렬이다'라는 귀무가설을 검정하는 과정이다. 이것은 개체-내 효과검정을 시행하기 전에 오차항의 분산-공분산 행렬이 항등행렬에 비례한다는 가설에 대해서 타당성을 검토하고 Greenhouse-Geisser, Huynh-Feldt Epsilon을 계산해서 개체-내 효과검정의 F검정을 보정하는데 사용하게 된다. Epsilon값이 1보다 작아질수록 구형성의 가설은 적절하지 않음을 나타내고 이후 보정의 정도가 크게 된다. Epsilon의 하한값은 1/(m-1)으로 계산하며 (m= 반복측정회수), 3번 반복 측정된 경우 1/(3-1) = 0.5, 4번 반복 측정하면 1/(4-1) = 0.33이 된다. (이래서 5번 미만으로 해야 한다고 하나?) Epsilon이 0.40보다 작게 계산된다면, GG나 HF correction을 하더라도 보정된 P값에 sphericity를 violation한 영향이 미치게 된다. 
Correction은 F값을 계산하는 df에 대한 보정이 가해지며, epsilon이 0.75보다 크면 HF correction을, 0.75보다 작거나 sphericity에 대한 정보가 없을 때에는 GG correction을 시행한다.
  
  
  
rstatix::anova_test는 sphericity검정을 시행해 주기 때문에 편리하고, partial eta square를 계산 (effect.size = "pes) 또는 generalized eta square (effect.size = "ges")를 Type I SS와 Type III SS에서 계산도 가능하다. 다만 이것들을 한번에 계산할 수 없기 때문에 같은 code를 변형하여 여러번 시행하여야 한다.  
R의 basic 명령어인 "aov"와 "afex::aov_car"를 이용해서 계산하는 방법도 아래 소개되어 있다.
```{r}
# RM ANOVA with "aov" for Type I SS
aov(observed ~ ws.factor + Error(case.no/ws.factor),
           data = mydata.long) -> one.rmanova.res1

  # Effect size: partial eta squared (Type I SS)
  effectsize::eta_squared(one.rmanova.res1,
                          partial = TRUE)

  # Effect size: Generalized eta squared (Type I SS)
  effectsize::eta_squared(one.rmanova.res1,
                          generalized = TRUE)
  
  # Effect size: Cohen's f, partial (Type I SS)
  effectsize::cohens_f(one.rmanova.res1) -> one.rmanova.f1
  
  one.rmanova.f1

# RM ANOVA with "afex::aov_car" for Type III SS
if (!requireNamespace("afex", quietly = TRUE)) {
  install.packages("afex")
}
  
afex::aov_car(observed ~ ws.factor + Error(case.no/ws.factor),
              data = mydata.long) -> one.rmanova.res3

  # Effect size: parital eta-squared (Type III SS)
  effectsize::eta_squared(one.rmanova.res3,
                          partial = TRUE)
  # Effect size: Generalized eta squared (Type III SS)
  effectsize::eta_squared(one.rmanova.res3,
                          generalized = TRUE)

    # Effect size: Cohen's f, partial (Type III SS)
  effectsize::cohens_f(one.rmanova.res3)

```
  
*two way RM ANOVA (ANOVA with one repeated measure factor and one between-subject factor)*  
```{r}
anova_test(observed ~ medication + ws.factor + medication*ws.factor + Error(case.no/ws.factor),
           data = mydata.long,
           #effect.size = "pes",
           #effect.size = "ges",
           #type = 1,
           #type = 3,
           detailed = TRUE) -> two.rmanova.result

get_anova_table(two.rmanova.result)

two.rmanova.result$`Mauchly's Test for Sphericity`


# RM ANOVA with "aov" for Type I SS
aov(observed ~ medication + ws.factor + medication*ws.factor + Error(case.no/ws.factor),
           data = mydata.long) -> two.rmanova.res1

  # Effect size: partial eta squared (Type I SS)
  effectsize::eta_squared(two.rmanova.res1,
                          partial = TRUE)

  # Effect size: Generalized eta squared (Type I SS)
  effectsize::eta_squared(two.rmanova.res1,
                          generalized = TRUE)
  
  # Effect size: Cohen's f, partial (Type I SS)
  effectsize::cohens_f(two.rmanova.res1) -> two.rmanova.f1
  
  two.rmanova.f1

# RM ANOVA with "afex::aov_car" for Type III SS

afex::aov_car(observed ~ medication + ws.factor + medication*ws.factor + Error(case.no/ws.factor),
              data = mydata.long) -> two.rmanova.res3

  # Effect size: parital eta-squared (Type III SS)
  effectsize::eta_squared(two.rmanova.res3,
                          partial = TRUE)
  # Effect size: Generalized eta squared (Type III SS)
  effectsize::eta_squared(two.rmanova.res3,
                          generalized = TRUE)

    # Effect size: Cohen's f, partial (Type III SS)
  effectsize::cohens_f(two.rmanova.res3) -> two.rmanova.f3
  
  two.rmanova.f3
```



# SESSION 3: BACK TO YOUR HOME – PREPARE FOR THE NEXT JOURNEY

## Session 3-1: Basic concepts of power analysis

## Session 3-2: Sample size calculation: R vs. G*Power
 
R에서 power analysis를 위해 필요한 package는 다음과 같다.  
pwr  
WebPower (for ANOVA series)
  
```{r}
if (!requireNamespace("pwr", quietly = TRUE)) {
  install.packages("pwr")
}

if (!requireNamespace("WebPower", quietly = TRUE)) {
  install.packages("WebPower")
}
```

### T-test
  
1. 등분산성이 확립되었을 때  
이전 session 2-3에서 t-test 이후 effect size Cohen's d를 저장해 두었다.
```{r}
# Effect size
cohend

pwr::pwr.t.test(d = cohend[1,1],
                sig.level = 0.05,
                power = 0.80,
                type = "two.sample",
                alternative = "greater") -> t.test.n

t.test.n

# Considering drop-out rate of 10%
t.test.n.do <- ceiling(t.test.n$n)/0.9

ceiling(t.test.n.do)
```
  
2. 등분산성이 확립되지 않을 때  
```{r}
cohend.ueq

poolsd <- effectsize::sd_pooled(t_test.value ~ group, data = mydata)
poolsd

pwr::pwr.t.test(d = cohend.ueq[1,1],
                sig.level = 0.05,
                power = 0.80,
                type = "two.sample",
                alternative = "greater") -> t.test.ueq.n
t.test.ueq.n

# Considering drop-out rate of 10%
t.test.ueq.n.do <- ceiling(t.test.ueq.n$n)/0.9

ceiling(t.test.ueq.n.do)
```

### Paired T-test

```{r}
pwr::pwr.t.test(d = cohend.pair[1,1],
                sig.level = 0.05,
                power = 0.8,
                type = "paired") -> t.test.pair.n

t.test.pair.n

# Considering drop-out rate of 10%
t.test.pair.n.do <- ceiling(t.test.pair.n$n)/0.9

ceiling(t.test.pair.n.do)

```

### Chi-square test

```{r}
chisq.res$parameter[[1]]

pwr::pwr.chisq.test(w = cramerv[1,1],
                    df = chisq.res$parameter[[1]],
                    sig.level = 0.05,
                    power = 0.8) -> chisq.n

chisq.n

# Considering drop-out rate of 10%
chisq.n.do <- ceiling(chisq.n$N)/0.9

ceiling(chisq.n.do)
```

### ANOVA

1. One-way ANOVA  
  
이전 ANOVA test에서 group의 수는 다음을 통해 3군임을 확인할 수 있다.
```{r}
table(mydata$medication)
```
  
One-way ANOVA의 표본수 계산에는 Cohen's f를 사용한다.  

```{r}
one.anova.f[1,2] -> f


pwr::pwr.anova.test(k = 3, # number of groups
                    f = f,
                    sig.level = 0.05,
                    power = 0.8) -> one.anova.n
one.anova.n
# Considering drop-out rate of 10%
one.anova.n.do <- ceiling(one.anova.n$n)/0.9

ceiling(one.anova.n.do)
```
각 군당 35명, 전체 105명의 환자수가 필요하다.  

2. Two-way ANOVA  
이전 session에서 시행한 two-way ANOVA는
  - 3가지 medications (예: 3가지 항구토제)
  - 2개 groups(예: 남/여, young age/old age)  
를 대상으로 검정한 것이다.  
이와 같은 상황에서 표본수 계산은 "WebPower::wp.kanova"를 이용하여 계산 할 수 있다. 계산을 위해 필요한 정보는 다음과 같다.  
a. Numerator degrees of freedom = df(medication) $\times$ df(group) = (3-1) $\times$ (2-1) = 2
b. effect size f  
c. Number of groups: No of medications $\times$ No of groups = 3 $\times$ 2 = 6  
d. alpha = 0.05 & power = 0.8  
  
```{r}
WebPower::wp.kanova(ndf = 2,
                    f = two.anova.f.i[3,2],
                    ng = 6,
                    alpha = 0.05,
                    power = 0.8) -> two.anova.n

two.anova.n

# Considering drop-out rate of 10%
two.anova.n.do <- ceiling(two.anova.n$n)/0.9

ceiling(two.anova.n.do)
```
전체 543명의 환자수가 필요하다.  

### RM ANOVA

1. RM ANOVA with one repeated factor (within-subject factor)  
  
RM ANOVA with one repeated factor의 표본수 계산은 WebPower::wp.rmanova를 이용할 수 있다.  
wp.rmanova를 이용하기 위한 정보들은 다음과 같다.  
a. number of groups (ng): 1
b. number of measurements (nm) = 4 (obs1 ~ obs4)
c. effect size: Cohen's f
d. nonsphericity correction coefficient (nscor) = 0.672
e. alpha & Power
f. type = 0, 1, 2:  The value "0" is for between-effect; "1" is for within-effect; and "2" is for interaction effect.  

effect size는 within-subject factor에 대한 값을 이용한다 (between-subject에 대한 변수가 이 분석에는 포함되지 않는다).  
```{r}
f = one.rmanova.f1[2,3]
```

Nonsphericity correction coefficient (epsilon)  
이전 실행된 결과에서 Sphericity corrections부분을 살펴보면
```{r}
one.rmanova.res$`Sphericity Corrections`
```
HFe (Huynh-Feldt epsilon)이 0.672이다.

Type는 하나의 within-subject factor (repeated measures factor)만 있는 분석이기 때문에 1 (for within-effect)를 선택하면 된다.

```{r}
WebPower::wp.rmanova(ng = 1,
                     nm = 4,
                     f = one.rmanova.f1[2,3],
                     nscor = one.rmanova.res$`Sphericity Corrections`[1,6], # = 0.672
                     alpha = 0.05, power = 0.80,
                     type = 1) -> one.rmanova.n
one.rmanova.n

# Considering drop-out rate of 10%
one.rmanova.n.do <- ceiling(one.rmanova.n$n)/0.9

ceiling(one.rmanova.n.do)
```

2. two way RM ANOVA (ANOVA with one repeated measure factor and one between-subject factor)  
  
반복측정 변수 한개와 군을 나누는 변수 한개인 경우이다.  
표본수 계산은 WebPower::wp.rmanova를 사용한다.  
  
a. number of groups (ng): 3
```{r}
table(mydata.long$medication)
```

b. number of measurements (nm) = 4 (obs1 ~ obs4)
```{r}
table(mydata.long$ws.factor)
```

c. effect size: Cohen's f  
이전 통계 결과는 medication에 따른 결과만 유의하게 차이 있는 것으로 나왔으며, interaction은 없다고 결론지어졌다. 그러나, 이 연습에서는 interaction이 있다고 가정하고, 표본수계산을 시행해보자. 따라서, f값은 medication:ws.factor에 해당하는 것을 사용한다.
```{r}
two.rmanova.f1

two.rmanova.f1[5,3] -> f
```

d. nonsphericity correction coefficient (nscor) = 0.672
```{r}
two.rmanova.result$`Sphericity Corrections`
```

e. alpha & Power
f. type = 0, 1, 2:  The value "0" is for between-effect; "1" is for within-effect; and "2" is for interaction effect

```{r}
WebPower::wp.rmanova(ng = 3,
                     nm = 4,
                     f = two.rmanova.f1[5,3],
                     nscor = two.rmanova.result$`Sphericity Corrections`[1,6], # = 0.672
                     alpha = 0.05, power = 0.80,
                     type = 2) -> two.rmanova.n
two.rmanova.n

# Considering drop-out rate of 10%
two.rmanova.n.do <- ceiling(two.rmanova.n$n)/0.9

ceiling(two.rmanova.n.do)
```

                                                                -End of File-